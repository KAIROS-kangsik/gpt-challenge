from langchain.document_loaders import SitemapLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores.faiss import FAISS
from langchain.schema.runnable import RunnablePassthrough, RunnableLambda
from langchain.prompts import ChatPromptTemplate
from langchain.chat_models import ChatOpenAI
from langchain.callbacks.base import BaseCallbackHandler

import streamlit as st

st.set_page_config(
    page_icon="ğŸ“œ",
    page_title="SiteGPT",
)

if "openai_api_key" not in st.session_state:
    st.session_state["openai_api_key"] = None

if "messages_memory" not in st.session_state:
    st.session_state["messages_memory"] = []


class ChatCallbackHandler(BaseCallbackHandler):

    message = ""

    def on_llm_start(self, *args, **kwargs):
        self.message_box = st.empty()

    def on_llm_end(self, *args, **kwargs):
        save_message(self.message, "ai")

    def on_llm_new_token(self, token, *args, **kwargs):
        self.message += token
        self.message_box.markdown(self.message)


try:
    llm = ChatOpenAI(
        temperature=0,
        model="gpt-4-turbo-preview",
        openai_api_key=st.session_state.openai_api_key,
    )

    choose_llm = ChatOpenAI(
        temperature=0,
        streaming=True,
        openai_api_key=st.session_state.openai_api_key,
        callbacks=[
            ChatCallbackHandler(),
        ],
    )
except:
    pass


give_score_prompt = ChatPromptTemplate.from_template(
    """
    ë‹¤ìŒ 'Context'ì— ìˆëŠ” ì •ë³´ë¡œë§Œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”. 'Context'ì— ì—†ëŠ” ì •ë³´ëŠ” ì ˆëŒ€ ë‹µë³€ì— í¬í•¨ì‹œí‚¤ì§€ ë§ˆì„¸ìš”.

    ë§Œì•½ 'Context'ì— ì§ˆë¬¸ì— ëŒ€í•œ ë‹µì´ ì—†ë‹¤ë©´, ë°˜ë“œì‹œ 'ëª¨ë¥´ê² ìŠµë‹ˆë‹¤.'ë¼ê³ ë§Œ ë‹µí•˜ê³ , ì„ì˜ì˜ ê°’ì„ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”.

    ë‹µë³€ í›„, ë‹µë³€ì˜ ì •í™•ì„±ì„ 0~5ì ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”.  
    - 5: 'Context'ì— ê¸°ë°˜í•œ ì™„ì „íˆ ì •í™•í•œ ë‹µë³€  
    - 0: 'Context'ì— ë‹µì´ ì—†ê±°ë‚˜ í‹€ë¦° ê²½ìš°  

    0ì ì¸ ê²½ìš°ì—ë„ ë‹µë³€ì˜ ì ìˆ˜ë¥¼ 'ë°˜ë“œì‹œ' í¬í•¨ì‹œí‚¤ì„¸ìš”.

    Context: {context}

    Examples:

    Question: ë‹¬ì€ ì–¼ë§ˆë‚˜ ë©€ë¦¬ ìˆë‚˜ìš”?
    Answer: ë‹¬ì€ 384,400km ë–¨ì–´ì ¸ ìˆìŠµë‹ˆë‹¤.
    Score: 5

    Question: íƒœì–‘ì€ ì–¼ë§ˆë‚˜ ë©€ë¦¬ ìˆë‚˜ìš”?
    Answer: ëª¨ë¥´ê² ìŠµë‹ˆë‹¤.
    Score: 0

    ë‹¹ì‹  ì°¨ë¡€ì˜ˆìš”!

    Question: {question}
"""
)


def ask_each_doc(inputs):
    docs = inputs["context"]
    question = inputs["question"]
    chain = give_score_prompt | llm
    answer_array = []
    for doc in docs:
        result = chain.invoke(
            {
                "context": doc.page_content,
                "question": question,
            }
        )
        answer_array.append(result)
    result_object = {
        "question": question,
        "answers": answer_array,
    }
    # st.write(docs, question)
    return result_object


def save_message(message, role):
    st.session_state.get("messages_memory").append(
        {
            "content": message,
            "role": role,
        }
    )


choose_prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            """
ë‹¹ì‹ ì€ ì•„ë˜ì˜ answers ë¦¬ìŠ¤íŠ¸ì—ì„œ ì§ˆë¬¸ê³¼ ê°€ì¥ ê´€ë ¨ì´ ê¹Šê³ , ë™ì‹œì— ê°€ì¥ ë†’ì€ ì ìˆ˜ë¥¼ ê°€ì§„ ë‹µë³€ì„ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.

ì„ íƒí•œ ë‹µë³€ì˜ í…ìŠ¤íŠ¸ë¥¼ ê·¸ëŒ€ë¡œ ì¶œë ¥í•´ ì£¼ì„¸ìš”. ë‹¹ì‹ ì˜ ì¶œë ¥ì´ ë°”ë¡œ ìµœì¢… ë‹µë³€ì´ ë˜ë¯€ë¡œ, ì–´ë–¤ ì¶”ê°€ì ì¸ í…ìŠ¤íŠ¸, ì ‘ë‘ì‚¬, ì ìˆ˜ ë“±ì„ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”. ì˜¤ì§ ì„ íƒí•œ ë‹µë³€ì˜ ì›ë¬¸ ìì²´ë§Œ ì¶œë ¥í•´ì•¼ í•©ë‹ˆë‹¤.

ì˜ˆë¥¼ ë“¤ì–´, ë§Œì•½ ì„ íƒí•œ ë‹µë³€ì´ 'í•œêµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤.'ë¼ë©´, ì¶œë ¥ì€ ë‹¤ìŒê³¼ ê°™ì•„ì•¼ í•©ë‹ˆë‹¤:

í•œêµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤.

ì£¼ì˜:
- 'Answer: ', 'ë‹µë³€: ' ë“±ì˜ ì ‘ë‘ì‚¬ë¥¼ ë¶™ì´ì§€ ë§ˆì„¸ìš”.
- ë‹µë³€ì„ ë”°ì˜´í‘œë¡œ ê°ì‹¸ì§€ ë§ˆì„¸ìš”.
- ì ìˆ˜ë‚˜ ë‹¤ë¥¸ ì„¤ëª…ì„ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.
- ì„ íƒí•œ ë‹µë³€ì˜ í…ìŠ¤íŠ¸ë¥¼ ì •í™•íˆ ê·¸ëŒ€ë¡œ ì¶œë ¥í•´ ì£¼ì„¸ìš”.

í•­ìƒ í•œê¸€ë¡œë§Œ ëŒ€ë‹µí•´ ì£¼ì„¸ìš”.

Answers list: {answers}
""",
        ),
        ("human", "{question}"),
    ]
)


def choose_answer(inputs):
    question = inputs["question"]
    answers = inputs["answers"]
    chain = choose_prompt | choose_llm

    answers = "\n\n".join(answer.content for answer in answers)
    result = chain.invoke(
        {
            "answers": answers,
            "question": question,
        }
    )
    return result


def page_parse(soup):
    astro_fxeopwe4 = soup.find("div", class_="astro-fxeopwe4")
    if astro_fxeopwe4:
        astro_fxeopwe4.decompose()
    card_grid = soup.find("div", class_="card-grid")
    if card_grid:
        card_grid.decompose()
    astro_breadcrumbs = soup.find("astro-breadcrumbs")
    if astro_breadcrumbs:
        astro_breadcrumbs.decompose()
    button = soup.find("div", class_="!mt-0 self-center")
    if button:
        button.decompose()

    select_overview_html = soup.find("main", class_="astro-bguv2lll")

    if select_overview_html:
        title = select_overview_html.find("h1", id="_top")
        title_text = title.get_text(strip=True) if title else "No title found"

        content = select_overview_html.find(
            "div", class_="sl-markdown-content astro-cedpceuv"
        )
        content_text = content.get_text(strip=True) if content else "No content found"

        text = f"Title: {title_text}\n\ncontent: {content_text}"
        return text
    return ""


@st.cache_resource(show_spinner="ì‚¬ì´íŠ¸ ì½ëŠ”ì¤‘...")
def split_and_retrieve(url):
    loader = SitemapLoader(
        url,
        filter_urls=[
            "https://developers.cloudflare.com/ai-gateway/*",
            "https://developers.cloudflare.com/vectorize/*",
            "https://developers.cloudflare.com/workers-ai/*",
        ],
        parsing_function=page_parse,
    )
    splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
        chunk_size=1000,
        chunk_overlap=200,
    )
    docs = loader.load_and_split(text_splitter=splitter)
    vector_store = FAISS.from_documents(docs, OpenAIEmbeddings())
    # st.write(docs)
    return vector_store.as_retriever()
    # return docs


def paint_messages():
    if len(st.session_state.get("messages_memory")):
        for obj in st.session_state.get("messages_memory"):
            with st.chat_message(obj["role"]):
                st.markdown(obj["content"])


with st.sidebar:
    docs = None
    if not st.session_state.openai_api_key:
        st.markdown(
            """
        ### OpenAI API í‚¤ ì…ë ¥
        1. https://platform.openai.com/account/api-keys ì—ì„œ API í‚¤ë¥¼ ë°œê¸‰ë°›ìœ¼ì„¸ìš”.
        2. ë°œê¸‰ë°›ì€ API í‚¤ë¥¼ ì•„ë˜ì— ì…ë ¥í•˜ì„¸ìš”.
        3. API í‚¤ëŠ” ì„¸ì…˜ì—ë§Œ ì €ì¥ë˜ë©°, ë¸Œë¼ìš°ì €ë¥¼ ë‹«ìœ¼ë©´ ì‚¬ë¼ì§‘ë‹ˆë‹¤.
        """
        )
        api_key = st.text_input("OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”", type="password")
        if api_key:
            st.session_state.openai_api_key = api_key
            st.success("API í‚¤ê°€ ì…ë ¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
            st.rerun()
        elif not st.session_state.get("openai_api_key"):
            st.warning("API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
    else:
        st.success("APIì…ë ¥ ì„±ê³µ!")
        st.write("Cloudflare ê³µì‹ë¬¸ì„œë¥¼ ìœ„í•œ SiteGPTì— ì˜¤ì‹ ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤.")

if st.session_state["openai_api_key"]:
    st.markdown(
        """
    # SiteGPT

    ì›¹ì‚¬ì´íŠ¸ Cloudflareì˜ ë‚´ìš©ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”.
"""
    )
    url = "https://developers.cloudflare.com/sitemap-0.xml"
    retrieve = split_and_retrieve(url)
    # with st.chat_message("human"):
    query = st.chat_input()

    if query:
        save_message(query, "human")
        paint_messages()

        chain = (
            {
                "context": retrieve,
                "question": RunnablePassthrough(),
            }
            | RunnableLambda(ask_each_doc)
            | RunnableLambda(choose_answer)
        )
        with st.chat_message("ai"):
            chain.invoke(query)

        st.rerun()

if len(st.session_state.get("messages_memory")):
    if st.session_state.get("messages_memory")[-1]["role"] == "ai":
        paint_messages()
